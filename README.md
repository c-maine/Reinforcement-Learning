# Reinforcement-Learning

**Structure of this repo**

Experiments and implementations of Reinforcement Learning algorithms:

1. [Value_iteration_vF.ipynb](https://github.com/c-maine/Reinforcement-Learning/blob/master/Value_iteration_vF.ipynb) is an implementation of the Value Iteration for the Gambler's Problem (Exercise Reinforcement Learning: an Introduction, 2nd edition" by Sutton & Barto (2018)

2. [Gaussian_Processes_vF.ipynb](https://github.com/c-maine/Reinforcement-Learning/blob/master/Gaussian_Processes_vF.ipynb) is a replication of the results from Figures 2.4 and 2.5 in Rasmussen & Williams Gaussian Processes for Machine Learning

3. [chapelle_li_vF.ipynb](https://github.com/c-maine/Reinforcement-Learning/blob/master/chapelle_li_vF.ipynb) is an empirical evaluation of Thompson Sampling and replication of the 2010 paper by [Chapelle and Li](https://papers.nips.cc/paper/4321-an-empirical-evaluation-of-thompson-sampling.pdf)

4. [Bayesian_optimisation_vF.ipynb](https://github.com/c-maine/Reinforcement-Learning/blob/master/Bayesian_optimisation_vF.ipynb) implements Bayesian optimisation for UCB, EI and PI acquisition functions on a Branin-Hoo landscape using Gaussian Processes

5. [TD_LSTD_vF.ipynb](https://github.com/c-maine/Reinforcement-Learning/blob/master/TD_LSTD_vF.ipynb) is an implementation of the Temporal Difference and Least Squares Temporal Difference Learning algorithms. 

**Example**

The image below is taken from the [Bayesian_optimisation_vF.ipynb](https://github.com/c-maine/Reinforcement-Learning/blob/master/Bayesian_optimisation_vF.ipynb) and is a 3D visualisation of the Branin Hoo function on which Bayesian optimisation is performed.

![alt text](https://github.com/c-maine/Reinforcement-Learning/blob/master/brian-hoo.png)




